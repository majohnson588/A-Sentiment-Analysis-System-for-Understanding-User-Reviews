{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udcd8 IMDb Sentiment Analysis\n", "This notebook implements sentiment classification on IMDb reviews using pre-trained Word2Vec embeddings and logistic regression."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 1: Download required NLTK resources\n", "import nltk\n", "nltk.download('punkt')\n", "nltk.download('stopwords')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 2: Load IMDb dataset using Hugging Face datasets\n", "from datasets import load_dataset, concatenate_datasets\n", "dataset = load_dataset(\"imdb\")\n", "pos = dataset['train'].filter(lambda x: x['label'] == 1).select(range(2500))\n", "neg = dataset['train'].filter(lambda x: x['label'] == 0).select(range(2500))\n", "full_dataset = concatenate_datasets([pos, neg]).shuffle(seed=42)\n", "texts = full_dataset['text']\n", "labels = full_dataset['label']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 3: Preprocess text and generate sentence embeddings\n", "import numpy as np\n", "import gensim.downloader as api\n", "from nltk.tokenize import word_tokenize\n", "from nltk.corpus import stopwords\n", "from tqdm import tqdm\n", "\n", "w2v = api.load(\"word2vec-google-news-300\")\n", "def preprocess(text):\n", "    tokens = word_tokenize(text.lower())\n", "    return [t for t in tokens if t.isalpha() and t not in stopwords.words('english')]\n", "\n", "def doc_vector(text):\n", "    words = preprocess(text)\n", "    vectors = [w2v[w] for w in words if w in w2v]\n", "    return np.mean(vectors, axis=0) if vectors else np.zeros(300)\n", "\n", "X = np.array([doc_vector(t) for t in tqdm(texts, desc=\"Vectorizing\")])\n", "y = np.array(labels)\n", "print(\"\u2705 Vectorization complete.\")\n", "print(\"X shape:\", X.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 4: Train logistic regression model and evaluate performance\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "model = LogisticRegression(max_iter=1000)\n", "model.fit(X_train, y_train)\n", "y_pred = model.predict(X_test)\n", "\n", "print(\"\ud83d\udcca Evaluation Metrics:\")\n", "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n", "print(\"Precision:\", precision_score(y_test, y_pred))\n", "print(\"Recall:\", recall_score(y_test, y_pred))\n", "print(\"F1 Score:\", f1_score(y_test, y_pred))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 5: Visualize results\n", "import matplotlib.pyplot as plt\n", "scores = {\n", "    'Accuracy': accuracy_score(y_test, y_pred),\n", "    'Precision': precision_score(y_test, y_pred),\n", "    'Recall': recall_score(y_test, y_pred),\n", "    'F1 Score': f1_score(y_test, y_pred)\n", "}\n", "plt.figure(figsize=(6,4))\n", "plt.bar(scores.keys(), scores.values())\n", "plt.ylim(0, 1)\n", "plt.title(\"Sentiment Classifier Performance\")\n", "plt.ylabel(\"Score\")\n", "plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}